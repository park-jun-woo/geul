## **계층적 캐스케이드 쿼리: 4비트 양자화, ANN, 단일 레이어 트랜스포머를 결합한 초거대 지식베이스 실시간 검색 시스템**

**Hierarchical Cascade Query: A Real-time Search System for Very Large-Scale Knowledge Bases Combining 4-bit Quantization, ANN, and a Single-Layer Transformer**

### **초록 (Abstract)**

초거대 지식베이스(VLKB)에서 실시간으로 정확한 정보를 검색하는 것은 현대 AI 시스템의 핵심적인 과제이지만, 기존 방식들은 **속도, 정확도, 비용** 사이의 삼각 딜레마에 직면해 있다. 본 논문은 GEUL 아키텍처의 WMS(World Management System)에서 이 문제를 해결하기 위해 설계된 새로운 **3단계 계층적 캐스케이드 쿼리(Hierarchical Cascade Query)** 아키텍처를 제안한다. 이 아키텍처는 '점진적 정제(Progressive Refinement)' 철학에 기반하여, 거대한 후보군을 단계적으로 효율적으로 줄여나간다. **1단계**에서는 10억 개 이상의 전체 객체를 16개의 최상위 개념으로 분류하는 **4비트 양자화 인덱스**를 통해 99.9%의 관련 없는 데이터를 초고속으로 필터링한다. **2단계**에서는 남은 후보군을 대상으로 **8비트 양자화 ANN(근사 최근접 이웃)** 검색을 수행하여 의미적으로 가장 유사한 수천 개의 후보를 선별한다. 마지막 **3단계**에서는 이 소수의 후보군을 대상으로 **단일 레이어 트랜스포머**가 컨텍스트와 관계를 정밀하게 재랭킹하여 최종 결과를 도출한다. 이 계층적 접근을 통해 본 시스템은 기존 방식 대비 1000배 향상된 속도와 1/1000 수준의 메모리 효율성을 달성하면서도 97-99%의 높은 정확도를 유지하는 것을 목표로 한다.

---
### **1. 서론 (Introduction)**

지식의 규모가 기하급수적으로 증가함에 따라, 10억 개 이상의 객체를 포함하는 초거대 지식베이스에서 사용자의 질의에 실시간으로 응답하는 능력은 AI 서비스의 성패를 가르는 핵심 요소가 되었다. 그러나 현재의 기술들은 명확한 한계를 가진다. 전통적인 데이터베이스는 의미적, 관계적 검색에 취약하며, 벡터 데이터베이스 기반의 의미 검색은 대규모 환경에서 막대한 메모리 비용과 지연 시간을 유발한다. RAG(Retrieval-Augmented Generation) 패러다임 역시 검색 단계의 성능에 따라 전체 답변의 품질이 좌우되는 문제를 안고 있다.

본 논문은 이러한 **'속도-정확도-비용'**의 삼각 딜레마를 해결하기 위한 새로운 접근법으로, GEUL 아키텍처의 **3단계 캐스케이드 쿼리**를 제안한다. 이는 마치 거친 체에서 시작해 점점 고운 체로 걸러내듯, 최소한의 비용으로 후보군을 점진적으로 줄여나가 최종적으로 가장 정확한 답을 찾는 방식이다.

---
### **2. 3단계 캐스케이드 쿼리 아키텍처**

본 아키텍처의 핵심은 각 단계가 이전 단계의 결과물을 입력받아, 더 정교하지만 더 적은 데이터에 대해 연산을 수행하여 전체 파이프라인의 효율을 극대화하는 데 있다.



#### **2.1. Stage 0: 4비트 개념 필터 - 광역 제거**

* **원리**: 모든 지식 객체를 16개의 최상위 개념(예: `물질/정보`, `생물/무생물`, `추상개념` 등)으로 강제 양자화하여, 각 객체에 4비트의 개념 코드를 부여한다.
* **작동**: "사과"에 대한 검색 시, '생물/식물' 카테고리에 해당하는 4비트 코드를 가진 객체들만 남기고 나머지는 모두 버린다. 10억 개의 객체는 이 단계에서 약 100만 개로 줄어든다 (99.9% 제거).
* **장점**: 인덱스 크기가 극도로 작아(10억 객체 기준 약 500MB) 메모리에 상주 가능하며, 단순 비트 비교 연산이므로 CPU의 SIMD 가속을 통해 수백만 QPS(Query Per Second) 처리가 가능하다.

#### **2.2. Stage 1: ANN 의미 필터 - 정밀 조준**

* **원리**: Stage 0에서 살아남은 100만 개의 후보군을 대상으로, 고차원 벡터 공간에서 의미적으로 가장 가까운 이웃을 찾는 ANN 검색을 수행한다.
* **작동**: 쿼리 역시 동일한 벡터 공간으로 변환된 후, HNSW(Hierarchical Navigable Small World)와 같은 알고리즘을 통해 벡터 거리가 가장 가까운 상위 1만 개 내외의 후보군을 선별한다. 이때 벡터를 32비트 실수에서 **8비트 정수로 양자화**하여 메모리 사용량을 1/4로 줄이고 연산 속도를 4배 향상시킨다.
* **장점**: 개념적으로 관련이 있는 후보군 내에서, 실제 의미가 가장 유사한 객체들만을 정밀하게 조준하여 다음 단계의 부담을 획기적으로 줄여준다.

#### **2.3. Stage 2: 단일 레이어 트랜스포머 - 최종 심사**

* **원리**: 최종 후보 1만 개를 대상으로, 단순 유사도를 넘어 복잡한 컨텍스트와 관계를 이해할 수 있는 트랜스포머의 어텐션 메커니즘을 통해 최종 순위를 결정한다.
* **작동**: 질문 "의사가 멀리하는 빨간 과일"에 대해, ANN이 '사과'와 '딸기'를 모두 높은 순위로 가져왔더라도, 이 단계의 트랜스포머는 "An apple a day keeps the doctor away"라는 관계 지식(`서술 글오`)을 이해하여 '사과'에 압도적으로 높은 점수를 부여한다. 이때, 쿼리는 어텐션 연산을 위한 마스크(Mask)와 가중치로 컴파일되어 단일 레이어의 추론만으로 효율적인 재랭킹이 가능하다.
* **장점**: 앞선 단계들에서 발생할 수 있는 미세한 오류를 바로잡고, 가장 정확하며 맥락에 부합하는 답변을 사용자에게 제공하는 최종 심사관 역할을 한다.

---
### **3. 성능 및 효율 분석**

본 아키텍처는 단일 GPU에서 **초당 50,000 쿼리**를 처리하며 **총 0.02초 내외의 응답 속도**를 보이는 것을 목표로 한다. 10억 개의 512차원 벡터를 저장하는 데 필요한 총메모리는 약 **1.6GB**로, 기존의 순수 벡터DB 방식이 수 테라바이트(TB)를 요구하는 것에 비해 압도적인 효율성을 보인다.

---
### **4. 결론**

제안된 3단계 계층적 캐스케이드 쿼리 아키텍처는 극단적인 양자화, 근사 검색, 그리고 경량 트랜스포머 추론의 장점만을 계층적으로 결합하여, 초거대 지식베이스 검색의 '속도-정확도-비용' 딜레마를 해결하는 새로운 패러다임을 제시한다. 이는 향후 실시간 지식 검색을 요구하는 모든 AI 시스템의 핵심 기반 기술이 될 잠재력을 가지고 있다.