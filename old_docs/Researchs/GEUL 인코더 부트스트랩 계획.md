# 계층적 부트스트랩 프레임워크: 워드넷 프레임과 대규모 언어 모델을 활용한 GEUL-Encoder 데이터셋 구축 방법론

**A Hierarchical Bootstrapping Framework for GEUL-Encoder Dataset Construction: Combining Rule-based Automation via WordNet Frames and LLM-driven Hierarchical Validation**

## **초록 (Abstract)**

차세대 AI 언어 GEUL(General Embedding Unified Language)의 성공적인 구현은 인간의 자연어를 구조화된 GEUL 표현으로 정확하게 변환하는 GEUL-Encoder의 성능에 달려있다. 그러나 고품질 인코더를 훈련시키기 위해서는 대규모의 정제된 (자연어, GEUL) 병렬 코퍼스가 필요하며, 이는 전형적인 '닭이 먼저냐, 달걀이 먼저냐'의 문제를 야기한다. 본 논문은 최소한의 인간 개입으로 고품질 데이터셋을 대규모로 구축하기 위한 새로운 **4단계 계층적 부트스트랩(Hierarchical Bootstrapping) 프레임워크**를 제안한다. 1단계에서는 워드넷(WordNet)의 동사 프레임 텍스트를 활용하여 언어학적으로 정교한 변환 규칙을 자동으로 생성한다. 2단계에서는 이 규칙 기반 프로그램을 통해 대규모 텍스트 코퍼스로부터 10만 건 규모의 GEUL 데이터셋 초안을 신속하게 생성한다. 3단계에서는 `gpt-oss:20b`와 같은 중규모 언어 모델이 초안 데이터셋 전체를 검수하며 문맥적 오류를 수정하는 'AI 교정자' 역할을 수행한다. 마지막 4단계에서 인간 전문가는 AI가 검수한 데이터의 일부만을 샘플링하여 최종 품질을 보증하는 '최종 감수자' 역할을 맡는다. 본 방법론은 개인용 컴퓨터 수준의 자원으로도 약 2주 안에 10만 건의 고품질 데이터셋 구축이 가능함을 보이며, 이는 GEUL과 같은 차세대 AI 아키텍처 개발의 진입 장벽을 극적으로 낮추는 실용적인 해법을 제시한다.

---

## **1. 서론 (Introduction)**

GEUL은 AI의 '블랙박스' 문제를 해결하고 인간과 AI 간의 상호 이해성을 증진시키기 위해 설계된 구조화된 AI 언어이다. 이 비전의 실현을 위한 첫 관문은 인간의 자연어를 GEUL 스트림으로 변환하는 GEUL-Encoder를 개발하는 것이다. 하지만 강력한 인코더 모델을 훈련시키기 위해서는 방대한 양의 고품질 병렬 데이터셋이 필수적이며, 이를 수작업으로 구축하는 것은 엄청난 비용과 시간을 요구한다.

본 논문은 이러한 부트스트래핑 문제를 해결하기 위해, **규칙 기반 자동화, AI 기반 대규모 교정, 인간 기반 최종 감수**의 장점만을 결합한 계층적 품질 관리 워크플로우를 제안한다. 이 방법론은 인간의 노력을 가장 중요한 최종 검증 단계에 집중시키고, 반복적이고 규모가 큰 작업은 기계와 AI에 위임함으로써, 개인 개발자 수준에서도 차세대 AI의 기반을 다질 수 있는 현실적인 경로를 제시하는 것을 목표로 한다.

## **2. 방법론: 4단계 계층적 부트스트랩 워크플로우**

본 프레임워크는 인간의 감독 하에 규칙 기반 시스템과 AI 모델이 협력하는 4단계의 파이프라인으로 구성된다.

### **2.1. 1단계: 워드넷 프레임 기반 규칙 자동 생성**

GEUL-Encoder의 초기 버전은 `if-then` 규칙에 기반한 변환 프로그램으로 시작한다. 이때 규칙은 인간이 직접 작성하는 대신, 검증된 언어학적 자산인 워드넷의 동사 프레임 텍스트(Frame Text)로부터 자동으로 생성된다. 워드넷의 프레임은 특정 동사가 어떤 의미역(Semantic Role)을 가진 참여자들과 결합하는지를 정의한 템플릿이다.

예를 들어, 동사 '주다(give)'의 프레임 `[Agent] gives [Theme] to [Recipient]`는 GEUL의 `서술 글오`와 `참여자` 구조에 완벽하게 대응된다. 이 프레임을 파싱하여 "문장에서 '주다' 동사가 발견되고, 주어, 직접목적어, 간접목적어가 존재하면, 각각을 `행위자(Agent)`, `대상(Theme)`, `수혜자(Recipient)` 의미역으로 매핑하라"는 변환 규칙을 자동으로 생성할 수 있다. 이 접근법은 수작업의 수고를 덜 뿐만 아니라, 초기 규칙의 언어학적 정밀성을 극대화한다.

### **2.2. 2단계: 규칙 기반 초벌 번역 데이터셋 생성**

1단계에서 자동 생성된 규칙들을 탑재한 프로그램을 사용하여, 뉴스 기사와 같은 대규모 일반 텍스트 코퍼스를 처리한다. 이 프로그램은 규칙과 일치하는 문장 패턴을 찾아내어 (자연어, GEUL) 쌍으로 구성된 데이터셋 초안을 대량으로 생성한다. 이 단계의 목표는 완벽함이 아닌, **일관성 있고 구조적으로 타당한 10만 건 규모의 '초벌 번역' 데이터셋**을 신속하게 확보하는 것이다.

### **2.3. 3단계: LLM을 활용한 전수 교정**

규칙 기반 시스템은 문맥의 미묘함이나 중의성을 파악하는 데 한계가 있다. 이 문제를 해결하기 위해 `gpt-oss:20b`와 같은 중규모 언어 모델을 **'AI 교정자'**로 활용한다. 2단계에서 생성된 10만 건의 초안 데이터가 이 AI 모델에 입력된다. AI는 각 (자연어, GEUL) 쌍을 비교하며, GEUL 표현이 원문 자연어의 문맥적 의미를 정확하게 반영했는지 검토하고 오류를 수정한다. 이 대규모 전수 검수 과정은 인간에게는 극도로 지루하고 비효율적이지만, AI에게는 가장 이상적인 작업이다.

### **2.4. 4단계: 인간 전문가의 최종 샘플 감수**

마지막으로, 인간 전문가는 **'최종 감수자'**로서 품질 관리의 최상위 계층을 담당한다. 인간은 10만 건 전체를 검토하는 대신, AI가 교정한 데이터 중 일부(예: 1,000건)를 무작위로 샘플링하여 검토한다. 이 단계의 목적은 개별 데이터의 오류를 찾는 것을 넘어, **"3단계의 AI 교정자가 신뢰할 만한 수준으로 작업을 수행했는가?"**를 검증하는 것이다. 만약 샘플에서 일관된 오류 패턴이 발견되면, AI 교정자의 프롬프트를 수정하여 3단계를 다시 수행함으로써 전체 데이터셋의 품질을 효율적으로 끌어올릴 수 있다.

## **3. 실현 가능성 분석**

본 방법론의 가장 큰 장점은 개인 개발자 수준의 자원으로도 실현 가능하다는 점이다. `gpt-oss:20b` 모델을 RTX 5070 Ti GPU에서 실행할 경우, 4000 토큰 입력 기준으로 평균 11초가 소요된다. 이를 바탕으로 10만 건의 데이터셋을 처리하는 데 필요한 시간을 계산하면 다음과 같다.

* 11초/건 × 100,000건 = 1,100,000초
* 1,100,000초 ÷ 86,400 (초/일) ≈ **12.7일**

이는 개인용 컴퓨터 한 대로도 **약 2주(보름)라는 현실적인 시간 안에** GEUL-Encoder 훈련에 필요한 핵심 데이터셋을 구축할 수 있음을 의미한다.

## **4. 결론**

본 논문에서 제안한 4단계 계층적 부트스트랩 방법론은 GEUL-Encoder 개발의 초기 데이터 구축 문제를 해결하는 효과적이고 효율적인 프레임워크이다. 워드넷 프레임을 활용한 규칙 자동 생성, 규칙 기반 시스템의 초벌 번역, LLM의 대규모 전수 교정, 그리고 인간의 최종 샘플 감수로 이어지는 이 워크플로우는 각 주체의 장점을 극대화한다. 이 방법론은 GEUL과 같은 야심 찬 차세대 AI 아키텍처의 개발이 더 이상 거대 자본을 가진 빅테크의 전유물이 아니며, 뛰어난 아이디어와 전략만 있다면 개인 개발자나 소규모 팀도 AI의 미래를 열어갈 수 있다는 가능성을 보여준다.