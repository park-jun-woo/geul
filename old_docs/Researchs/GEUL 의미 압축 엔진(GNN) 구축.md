## **제안서: GEUL 의미 압축 엔진(GNN) 구축을 위한 자기지도학습 프레임워크 v1.2**

### **초록 (Abstract)**

본 문서는 SEGLAM 아키텍처의 핵심 구성요소인 GNN(그래프 신경망) 기반 의미 압축 엔진을 구축하기 위한 구체적인 실행 프레임워크 v1.2를 제안합니다. GNN의 목표는 순차적인 `GEUL-Stream`을 입력받아, 그 안에 내재된 복잡한 관계 구조를 학습하여 최종 추론기(`GAT`)가 사용하기에 최적화된 고밀도 의미 벡터(`GEUL-NV`)를 생성하는 것입니다. 본 프레임워크는 **데이터 전처리, 이종 그래프 구성, 자기지도학습 기반 데이터셋 생성, 관계형 GNN(R-GCN) 모델링 및 학습, 그리고 체계적인 평가**까지의 전 과정을 상세히 정의합니다. 특히 `GEUL-Encoder` 훈련용으로 구축된 데이터셋을 GNN 학습에 재사용하고, '연결 예측(Link Prediction)' 자기지도학습 기법을 통해 GNN이 데이터의 구조적 문법을 스스로 터득하게 함으로써, 별도의 레이블링 비용 없이 고품질의 의미 압축 엔진을 개발하는 현실적인 경로를 제시합니다.

-----

### **1단계: 데이터 전처리 및 그래프 구성 (CPU)**

GNN 학습의 성패는 양질의 그래프 데이터 확보에 달려있습니다. 이 단계의 목표는 원본 `GEUL-Stream`으로부터 노이즈를 제거하고 정규화하여, 학습에 최적화된 \*\*'속성을 가진 이종 그래프(Attributed Heterogeneous Graph)'\*\*를 구성하는 것입니다.

#### **1.1 데이터 전처리 파이프라인**

1.  **GEUL-Stream 유효성 검증**:
      * 필수 `메타 글소`(절대ID, 확신도 등)의 존재 여부를 확인합니다.
      * `개체 참조`가 가리키는 대상이 존재하지 않는 경우(dangling reference)를 방지하기 위해 참조 무결성을 검사합니다.
2.  **노드 중복 제거 및 병합**:
      * 동일한 개체(예: '소크라테스')에 대해 임시 ID와 절대 ID가 혼용된 경우, 이를 정식 절대 ID로 통합합니다.
3.  **그래프 정규화**:
      * 허브 노드(Hub Node, 과도하게 많은 연결을 가진 노드)를 탐지하고, 관계의 중요도에 따라 엣지를 샘플링하거나 분리하여 처리합니다.
      * 최소 연결 임계값(노드당 평균 엣지 2.5개)에 미달하는 저품질 그래프는 학습 데이터에서 제외합니다.

#### **1.2 그래프 구성 규칙**

  * **노드 타입 정의**:
      * **EntityNode**: `개체 글오` (사람, 장소, 개념)
      * **StatementNode**: `서술 글오` (사실, 사건)
      * **ConnectionNode**: `연결 글오` (논리적 관계)
  * **엣지 타입 매핑**: `글오` 내부의 참조 정보를 바탕으로 다음과 같이 엣지를 생성합니다.
      * `AGENT`, `PATIENT`, `LOCATION`, `TEMPORAL`, `CAUSALITY`, `PREMISE`, `CONCLUSION` 등

#### **1.3 노드 속성(Feature) 정의**

  * **글오 타입 원핫 인코딩** (8차원)
  * **의미소 ID 임베딩** (64차원)
  * **시간 정보 DFC 인코딩** (16차원)
  * **확신도 스칼라 값** (1차원)
  * **총 89차원 초기 특성 벡터**

-----

### **2단계: 자기지도학습 데이터셋 생성**

별도의 정답지 없이, 원본 데이터 스스로가 '선생님'이 되도록 데이터셋을 가공합니다.

  * **학습 데이터 밸런싱**:
      * **노드 타입별 균형**: 전체 데이터셋에서 `EntityNode:StatementNode:ConnectionNode`의 비율을 약 `6:3:1`로 유지합니다.
      * **엣지 타입별 샘플 보장**: 모든 엣지 타입이 최소 1,000개 이상의 샘플을 갖도록 보장하며, 희귀 관계 타입은 오버샘플링합니다.
  * **계층적 엣지 제거 전략**:
      * **Level 1**: 직접 관계 (15% 제거)
      * **Level 2**: 2-hop 관계 (10% 제거)
      * **Level 3**: 추론 가능한 관계 (5% 제거)
  * **부정 샘플 생성 전략**:
      * **타입 호환** (의미적으로 가능하지만 틀린) 및 **타입 비호환** (의미적으로 불가능한) 부정 샘플을 **50:50 비율**로 생성합니다.

-----

### **3단계: R-GCN 모델 및 학습 전략 (GPU)**

#### **3.1 모델 아키텍처**

PyTorch Geometric을 기반으로 잔차 연결(Residual Connection)과 배치 정규화(Batch Normalization)를 포함한 R-GCN 모델을 구성하여 깊은 학습을 안정화합니다.

```go
// 더 구체적인 모델 구성
type GEULGNNModel struct {
    NodeEmbedding    *torch.Embedding  // 의미소 ID → 임베딩
    NodeTypeEmbedding *torch.Embedding // 타입 정보 임베딩
    
    RGCNLayers      []RGCNConv        // 3층 R-GCN
    BatchNorm       []BatchNorm1d     // 각 층마다 정규화
    ResidualConn    []Linear          // 잔차 연결
    
    OutputProjection Linear           // 최종 GEUL-NV 생성 (512차원)
    DropoutRate      float64          // 0.2
}
```

#### **3.2 학습 전략**

  * **다단계 학습 과정**:
    1.  **Warmup (5 epochs)**: 단순 직접 관계 예측
    2.  **Main Training (20 epochs)**: 복합 및 추론 관계 학습
    3.  **Fine-tuning (5 epochs)**: 대조 학습을 통한 의미 거리 최적화
  * **손실 함수 조합**:
      * **연결 예측 손실 (BCE Loss)**: 70%
      * **대조 학습 손실 (InfoNCE Loss)**: 20%
      * **정규화 손실 (L2 Regularization)**: 10%

-----

### **4단계: 평가 및 벤치마킹**

#### **4.1 평가 프레임워크**

1.  **구조 학습 평가 (연결 예측)**:
      * 직접 관계: **Hits@1 \> 0.8**
      * 2-hop 관계: **Hits@3 \> 0.6**
2.  **의미 품질 평가 (GEUL-NV)**:
      * 동일 개체 일관성: **코사인 유사도 \> 0.9**
      * 유사 관계 클러스터링: **실루엣 점수 \> 0.7**
3.  **실용성 평가 (다운스트림 태스크)**:
      * 생성된 `GEUL-NV`를 `GAT`의 입력으로 사용했을 때, 최종 추론 성능이 얼마나 향상되는지 측정합니다.

#### **4.2 성능 벤치마킹**

  * **비교 기준선(Baseline) 설정**:
      * 단순 평균 풀링 (GNN 없음)
      * GraphSAGE (일반적인 동종 그래프 GNN)
      * HGT (이종 그래프 트랜스포머)
  * **목표**: 제안하는 **GEUL-GNN이 모든 베이스라인 모델 대비 주요 메트릭에서 15% 이상 높은 성능**을 달성하는 것을 목표로 합니다.

-----

### **5단계: 구현 계획**

#### **5.1 실험 설계**

다음 요소들에 대한 A/B 테스트를 통해 최적의 구성을 찾습니다.

  * 노드 특성 조합 (89차원 vs 128차원 vs 64차원)
  * 엣지 제거 비율 (15% vs 20% vs 25%)
  * 손실 함수 가중치 조합 (70:20:10 vs 60:30:10)
  * GNN 깊이 (2층 vs 3층 vs 4층)

#### **5.2 견고성 및 복구**

  * **에러 핸들링**: 그래프 파싱 실패 시 복구, 메모리 부족 시 배치 크기 자동 조정, 학습 발산 탐지 및 자동 중단 기능을 구현합니다.
  * **체크포인트**: 학습 중단 시에도 손실 없이 복구할 수 있도록 체크포인트 기반의 저장 및 복구 기능을 구현합니다.

#### **5.3 구현 우선순위**

  * **Phase 1 (1주): 핵심 파이프라인 구축**
      * `GEUL-Stream` → 그래프 변환기 및 기본 R-GCN 모델 구현
  * **Phase 2 (1주): 고도화**
      * 데이터 품질 관리 모듈, 평가 메트릭, 하이퍼파라미터 튜닝 자동화 구현
  * **Phase 3 (3일): 통합 테스트 및 문서화**
      * 전체 파이프라인 통합, 성능 벤치마크 수행, 최종 결과 문서화 및 데모 준비