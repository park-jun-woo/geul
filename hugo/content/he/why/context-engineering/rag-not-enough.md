---
title: "למה RAG לא מספיק"
weight: 2
date: 2026-02-26T12:00:11+09:00
lastmod: 2026-02-26T12:00:11+09:00
tags: ["RAG", "חיפוש", "embedding"]
summary: "להיראות רלוונטי ולהיות רלוונטי זה לא אותו דבר"
author: "ג'ונו פארק"
authorLink: "https://parkjunwoo.com/1/about"
image: "/images/og-default.webp"
---

## להיראות רלוונטי ולהיות רלוונטי זה לא אותו דבר.

---

## RAG הוא הסטנדרט הנוכחי

נכון ל-2024, RAG הוא הדרך הנפוצה ביותר שבה ארגונים מפעילים LLM.

Retrieval-Augmented Generation.
חפש מסמכים חיצוניים, הכנס אותם להקשר, ותן למודל לענות על בסיסם.

RAG עובד.
הוא מאפשר ל-LLM להתייחס למסמכים פנימיים שלא אומנו עליהם.
הוא מאפשר להם לשקף מידע עדכני.
הוא מפחית הזיות באופן משמעותי.

בלי RAG, אימוץ LLM בארגונים היה הרבה יותר איטי.
RAG הוא טכנולוגיה שראויה לכבוד.

אבל ל-RAG יש מגבלות יסודיות.
המגבלות האלה לא נפתרות על ידי בניית RAG טוב יותר.
הן נובעות מהנחת היסוד של RAG עצמו.

---

## איך RAG עובד

הליבה של RAG היא שלושה שלבים.

**שלב 1: פצל מסמכים לקטעים.**
קובצי PDF, ויקי, מסמכים פנימיים מחולקים לגדלים קבועים (בדרך כלל 200--500 טוקנים).

**שלב 2: המר כל קטע לוקטור embedding.**
וקטור ממשי בעל מאות עד אלפי ממדים.
"המשמעות" של הטקסט ממופה לנקודה אחת במרחב וקטורי.

**שלב 3: כשמגיעה שאילתה, מצא וקטורים דומים.**
גם השאילתה מומרת לוקטור.
5--20 הקטעים עם הדמיון הגבוה ביותר ב-cosine נבחרים ומוכנסים להקשר.

פשוט ואלגנטי.
וכאן טמונות שלוש בעיות יסודיות.

---

## בעיה 1: דומה אינו רלוונטי

דמיון embedding מודד "האם שני טקסטים משתמשים במילים דומות בהקשרים דומים."

זו אינה רלוונטיות.

דוגמה.

שאילתה: "מה היו הכנסות Apple ברבעון 3 של 2024?"

קטעים שחיפוש embedding עשוי להחזיר:
- "הכנסות Apple ברבעון 3 של 2024 היו 94.9 מיליארד דולר." -- רלוונטי
- "הכנסות Apple ברבעון 3 של 2023 היו 81.8 מיליארד דולר." -- דומה אבל תקופה אחרת
- "הכנסות Samsung Electronics ברבעון 3 של 2024 היו 79 טריליון וון." -- דומה אבל חברה אחרת
- "לפאי תפוחים יש כ-296 קלוריות." -- חפיפת מילות מפתח

דמיון embedding לא יכול להבחין בין ארבעת אלה.
במרחב הוקטורי, "הכנסות Apple" מתקבצות באזור אחד.
בין אם זה 2023 או 2024, Apple או Samsung --
מרחק וקטורי לא מפריד ביניהם באופן אמין.

הוספת reranker משפרת את המצב.
אבל גם reranker קורא ושופט טקסט בשפה טבעית,
ולכן בעיית העמימות היסודית נשארת.

חיפוש מבוסס מבנה סמנטי הוא שונה.
אם לישות "Apple" יש מזהה ייחודי,
היא לעולם לא תתבלבל עם "apple" הפרי.
אם "רבעון 3 2024" הוא שדה זמן,
הוא נבדל מכנית מ-"רבעון 3 2023."

אין צורך לחשב דמיון.
האם זה תואם או לא? כן או לא.

---

## בעיה 2: קטעים אינם יחידות משמעות

תסתכל שוב על השלב הראשון של RAG.
"פצל מסמכים לקטעים."

ה"פיצול" הזה הוא הבעיה.

כשמפצלים מסמך ליחידות של 500 טוקנים,
המשמעות נחתכת באמצע.
פסקה משתרעת על שני קטעים.
ההנחה והמסקנה של טיעון מופרדות.

"יי סון-שין התמודד עם 133 ספינות עם 12 בלבד בקרב מיונגניאנג" נמצא בקטע A,
ו-"חוקרים חולקים על המספרים האלה" נמצא בקטע B.
אם רק קטע A נשלף עבור שאילתה,
מידע הוודאות נכנס להקשר כשהוא כבר אבוד.

להגדיל קטעים? הם צורכים יותר מהחלון.
להקטין קטעים? יותר הקשר נחתך.
להוסיף חפיפה? מבזבזים את החלון על כפילויות.

לא משנה איך מכווננים, הבעיה היסודית זהה.
פיצול טקסט בשפה טבעית לפי ספירת טוקנים
זהה לפיצול משמעות לפי ספירת טוקנים.
למשמעות יש גודל טבעי,
וחלוקה שלה ביחידה לא קשורה גורמת לבעיות.

בייצוג מובנה, יחידות המשמעות הן מפורשות.
פרדיקציה אחת היא קשת אחת.
קשת לא מפוצלת.
החיפוש פועל ברמת הקשת.
אין חיתוך באמצע המשמעות.

---

## בעיה 3: איכות התוצאות המאוחזרות אינה ידועה

RAG החזיר 5 קטעים.
לפני הכנסת 5 אלה להקשר, יש שאלות שצריך לשאול.

מה המקור של המידע הזה?
מה תאריך הייחוס?
כמה הוא ודאי?
האם 5 אלה סותרים זה את זה?

בקטעי שפה טבעית, אי אפשר לדעת את הדברים האלה.

המקור עשוי או לא עשוי להיות מוזכר איפשהו בקטע כשפה טבעית.
ייחוס הזמן עשוי להיות איפשהו במסמך, או שהוא אבד כשהקטע פוצל.
לוודאות אין מקום מובנה בשפה טבעית, ולכן היא כמעט תמיד חסרה.
בדיקת סתירות דורשת קריאת כל 5 הקטעים והסקה עליהם.

בסופו של דבר, צריך להאציל את שיפוט האיכות ל-LLM.
משתמשים ב-RAG כדי להפחית עלויות קריאה ל-LLM,
אבל קוראים ל-LLM כדי לאמת תוצאות RAG.

בייצוג מובנה, מקור, זמן וודאות הם שדות.
"הוצא הצהרות ללא מקור" זו שורת שאילתה אחת.
"הוצא מידע לפני 2023" זו השוואת שדה אחת.
"הוצא ודאות מתחת ל-0.5" זו השוואה מספרית אחת.
אין צורך בקריאה ל-LLM.

---

## הנחת היסוד של RAG

השורש של שלוש הבעיות האלה הוא דבר אחד.

RAG מחפש שפה טבעית כשפה טבעית.

המסמכים הם שפה טבעית.
הקטעים הם שפה טבעית.
ה-embeddings הם קירובים סטטיסטיים של שפה טבעית.
תוצאות החיפוש הן שפה טבעית.
מה שנכנס להקשר הוא שפה טבעית.

העמימות של שפה טבעית חודרת לכל הצינור.

החיפוש לא מדויק כי מחפשים תוכן עמום בצורתו העמומה.
ההקשר אובד כי מפצלים תוכן עמום לפי גודל שלא קשור למשמעות.
אימות בלתי אפשרי כי אי אפשר לחלץ מידע איכות מתוכן עמום.

רוב הניסיונות לשפר RAG פועלים בתוך ההנחה הזו.

להשתמש במודל embedding טוב יותר. -- הקירוב הסטטיסטי נהיה מעודן יותר, זה הכל.
להשתמש באסטרטגיית חלוקה טובה יותר. -- מיקומי הפיצול משתפרים, זה הכל.
להוסיף reranker. -- קוראים את השפה הטבעית פעם נוספת, זה הכל.
להשתמש בחיפוש היברידי. -- מערבבים מילות מפתח ודמיון, זה הכל.

כולם עובדים.
כולם נשארים בתוך המסגרת של שפה טבעית.
אף אחד מהם אינו יסודי.

---

## תנאים לחלופה יסודית

כדי לחרוג מגבולות RAG, ההנחה חייבת להשתנות.
לא לחפש שפה טבעית כשפה טבעית,
אלא לחפש ייצוגים מובנים באופן מובנה.

חלופה זו חייבת לעמוד בשלושה תנאים.

**חיפוש לפי התאמה, לא לפי דמיון.**
לא למצוא "דברים שנראים דומים"
אלא למצוא "דברים שתואמים."
האם המזהה תואם? האם זה בטווח הזמן?
כן או לא. לא הסתברות.

**יחידת המשמעות היא יחידת החיפוש.**
לא לפצל לפי ספירת טוקנים
אלא לאחסן לפי פרדיקציה ולחפש לפי פרדיקציה.
אין חיתוך באמצע המשמעות.

**מטא-נתונים מוטמעים במבנה.**
אין צורך לקרוא ל-LLM כדי לשפוט את איכות תוצאות החיפוש.
מקור, זמן וודאות הם שדות,
ולכן סינון מכני אפשרי.

כששלושת התנאים האלה מתקיימים,
החיפוש עובר מ-"ניחוש מועמדים סבירים"
ל-"אישור מה שתואם."

---

## RAG הוא טכנולוגיית מעבר

זה לא כדי לזלזל ב-RAG.

RAG היה התשובה הטובה ביותר בעולם שבו שפה טבעית הייתה כל מה שיש.
כשמסמכים היו שפה טבעית, ידע נשמר בשפה טבעית,
ו-LLM היו כלים שמעבדים שפה טבעית,
חיפוש שפה טבעית עם שפה טבעית היה הבחירה המתבקשת.

ו-RAG אכן עובד.
LLM עם RAG הוא הרבה יותר מדויק מאחד בלי.
זו עובדה.

אבל אם ההנחה של "עולם שבו שפה טבעית היא כל מה שיש" משתנה,
גם מעמדו של RAG משתנה.

אם ייצוגים מובנים קיימים,
RAG הופך לחזית שפועלת כ-"קלט שפה טבעית שמחפש במאגר מובנה."
שפה טבעית -> שאילתה מובנית -> חיפוש מובני -> תוצאות מובנות -> הקשר.

RAG לא נעלם.
ה-backend שלו משתנה.
מחיפוש דמיון embedding לחיפוש מבוסס מבנה סמנטי.

---

## סיכום

RAG הוא הסטנדרט הנוכחי להנדסת הקשר.
ויש לו שלוש מגבלות יסודיות.

1. **דומה ≠ רלוונטי.** דמיון embedding אינו מבטיח רלוונטיות. "נראה דומה" ו-"רלוונטי" הם דברים שונים.
2. **קטע ≠ משמעות.** פיצול לפי ספירת טוקנים חותך באמצע המשמעות. הנחות ומסקנות מופרדות. מידע ודאות אובד.
3. **שיפוט איכות בלתי אפשרי.** מקור, זמן וודאות של קטעים מאוחזרים לא ניתנים לקביעה מכנית. שיפוט שלהם דורש קריאה ל-LLM.

השורש של שלוש הבעיות הוא דבר אחד.
חיפוש שפה טבעית כשפה טבעית.

החלופה היסודית היא לשנות את ההנחה.
התאמה, לא דמיון.
פרדיקציה, לא קטעי טוקנים.
מטא-נתונים מוטמעים, לא שיפוט חיצוני.

RAG הוא טכנולוגיית מעבר.
הוא היה התשובה הטובה ביותר בעולם שבו שפה טבעית הייתה כל מה שיש.
כשההנחה הזו משתנה, ה-backend של RAG משתנה.
