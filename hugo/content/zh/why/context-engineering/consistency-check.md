---
title: "为什么一致性检查是必要的"
weight: 6
date: 2026-02-26T12:00:08+09:00
lastmod: 2026-02-26T12:00:08+09:00
tags: ["一致性", "矛盾", "连贯性"]
summary: "单独正确的信息放在一起可能是错误的"
author: "朴俊宇"
authorLink: "https://parkjunwoo.com/1/about"
image: "/images/og-default.webp"
---

## 单独正确的信息放在一起可能是错误的。

---

## 校验通过了。过滤也通过了。

机械校验过滤掉了格式错误。
过滤根据相关性、可信度和时效性进行了筛选。

剩下30条信息。
全部有效，全部相关，全部可信，全部是最新的。

你把这30条放进上下文？

不。
还有一件事必须检查。
这30条之间是否相互矛盾？

---

## 矛盾不是单条信息的属性

看这两条陈述。

- 来源：三星电子IR公告，2024年10月。"三星电子CEO：全永铉。"
- 来源：三星电子IR公告，2024年3月。"三星电子CEO：庆桂显。"

单独看，两条都有效。
格式正确，来源存在，时间存在，可信。
通过了校验。通过了过滤。

但当两条同时进入同一个上下文时，就有问题了。
三星电子的CEO是全永铉还是庆桂显？

两条陈述都没有错。
3月时，庆桂显是对的。10月时，全永铉是对的。
单独看，两条都对。
但当它们共存于上下文中时，LLM会混乱。

这就是一致性问题。
它不是来自单条信息，而是来自信息的集合。
校验检查单条信息。过滤检查单条信息。
一致性检查的是信息之间的关系。

---

## 矛盾的类型

上下文中的矛盾分为几种类型。

### 时间矛盾

最常见的。

同一实体的同一属性随时间变化，
不同时间点的值共存于上下文中。

"特斯拉CEO：埃隆·马斯克"和
"特斯拉股价：194美元"在同一个上下文中，
但CEO信息是2024年的，股价是2023年6月的。
LLM可能将它们视为同一时间点的信息。

更微妙的情况也会出现。
"韩国基准利率：3.50%"是2024年1月的，
"韩国消费者物价涨幅：2.0%"是2024年10月的。
两条都有效，都涉及韩国经济，
但有9个月的差距。
这个差距是否影响推理，取决于上下文。

### 来源间矛盾

不同来源对同一事实给出不同的值。

- 来源A："2024年全球AI市场规模：1840亿美元。"
- 来源B："2024年全球AI市场规模：2140亿美元。"

两条都不能被明确宣告为"错误"。
市场范围定义可能不同。测量方法可能不同。
但如果两条都在上下文中，
LLM必须选择一个、混合两个、或者陷入混乱。

### 推理矛盾

不是直接矛盾的值，
但放在一起时逻辑上不兼容。

"A公司市场份额：60%。"
"B公司市场份额：55%。"

每条都有效。但加起来是115%。
加上其余的竞争对手会超过100%。
其中一条要么来自不同时间，要么使用不同的市场定义，要么就是错误的。

这种矛盾看单条陈述找不到。
必须检查集合。

---

## LLM不善于处理矛盾

理论上，LLM应该能检测和解决矛盾。
"这两条信息在时间上不同，所以我基于更新的那条来回答。"

在实践中，情况不是这样。

**LLM倾向于信任上下文中的信息。**
把东西放进上下文这个行为本身就是一个信号，说的是"参考这个"。
当两条矛盾的信息同时存在时，
LLM倾向于引用两者而不是忽略一个。
结果是混合或混乱。

**矛盾检测需要推理。**
知道"CEO：全永铉"和"CEO：庆桂显"矛盾，
需要背景知识——在某一时点只有一个CEO。
检查市场份额之和是否超过100%需要算术。
这取决于LLM的推理能力。

**解决更加困难。**
即使检测到矛盾，也必须判断选择哪一方。
更新的那条？更可信的来源？被更多来源支持的？
如果把这个判断留给LLM，一致性无法保证。
面对同样的矛盾，它有时选A，有时选B。

结论是，矛盾进入上下文之后再处理，
代价昂贵且结果不确定。
矛盾必须在进入上下文之前解决。

---

## 为什么一致性检查在自然语言中很困难

假设你在检查30个自然语言块的一致性。

首先，你必须确定它们是否关于同一个主题。
"三星电子"、"Samsung Electronics"和"三星"是否指同一个实体。
在自然语言中，这是不确定的。
"三星"是指三星电子、三星物产还是三星生命，需要阅读上下文。

接着，你必须确定它们是否描述同一个属性。
"营收"、"总营收"和"毛营收"是否是同一回事。
"营业利润"、"营业利润"和"营业利润率"是同一个还是不同的。

接着，你必须提取时间参考。
"上个季度"是什么时候？"最近"是什么时候？"今年"是什么时候？

只有在做完所有这些之后，你才能最终比较两条陈述是否矛盾。

30条陈述有435个比较对。
每对都必须经过上述过程。
全部是LLM推理。
全部昂贵。
全部是概率性的。

---

## 结构化表示中的一致性检查

在结构化表示中，情况不同。

**实体识别是确定性的。**
"三星电子"这个实体有唯一标识符。
"Samsung Electronics"指向同一个标识符。
不需要推理来确定身份。

**属性是显式的。**
"营收"是一个有类型的属性。
"营业利润率"是一个不同的属性。
两个属性是否相同通过字段比较确认。

**时间是字段。**
有一个像"2024-Q3"这样的值。
不需要解释"上个季度"。
两条陈述是否在同一时间通过一个值比较确定。

当这三件事是确定性的时候，矛盾检测模式就可以机械化。

同一实体 + 同一属性 + 同一时间 + 不同值 = 矛盾。
同一实体 + 同一属性 + 不同时间 + 不同值 = 变化。不是矛盾。
不同实体 + 同一属性 + 同一时间 + 值之和 > 100% = 推理矛盾。

不需要LLM。
字段比较和算术。

不是所有矛盾都能被捕获。
"AI市场在增长"和"AI投资在下降"是否矛盾，
仍然需要语义判断。
但如果可机械检测的矛盾先被捕获，
就只剩下需要语义判断的情况了。
再一次，廉价的先行。

---

## 一致性检查的解决策略

检测到矛盾之后，必须解决。

解决策略因情境而异，但在结构化表示中可以被声明为策略。

**最新优先。** 同一实体的同一属性冲突时，选时间戳更新的那个。适合CEO、股价、人口等变化值。

**最高信任优先。** 选可信度更高的。或者如果定义了来源层级，选更高级别的来源。第一手来源 > 第二手来源 > 非官方来源。

**两者并呈。** 不解决矛盾。两条都放进上下文，但明确标记矛盾。"来源A说1840亿美元；来源B说2140亿美元。可能是定义差异。"让LLM在知晓矛盾的情况下推理。

**两者排除。** 如果矛盾无法解决，两边都排除。没有信息好过错误的信息。

在自然语言管道中，这些策略被作为自然语言写在提示词中。
"请优先考虑最新的信息。"
LLM是否始终遵循，又是一个概率问题。

在结构化表示中，这些策略被声明为策略。
"当同一实体+同一属性冲突时：最新时间戳优先。如果时间戳相同：最高可信度优先。如果可信度相同：两者并呈。"
由机器执行。不是概率。

---

## 在管道中的位置

一致性检查在过滤之后。

校验 -> 过滤 -> 一致性检查。

为什么是这个顺序？

校验过滤掉格式错误。
过滤移除不需要的信息。
一致性检查只需要处理通过校验和过滤的内容。

一致性检查比较的是对。
n条陈述有n(n-1)/2对。
1000条大约产生500,000对。30条产生435对。

如果校验和过滤将1000条减少到30条，
一致性检查的成本从500,000降到435——降低了一千倍。

顺序很重要。

---

## 总结

单独有效、相关且可信的信息，
作为集合聚在一起时可能相互矛盾。

矛盾有三种类型。
时间矛盾——不同时间点的值共存。
来源间矛盾——不同来源给出不同的值。
推理矛盾——单独有效，但组合在一起时逻辑不兼容。

LLM不善于处理矛盾。
它们倾向于信任上下文中的信息，
矛盾检测需要推理，
解决的一致性无法保证。

在自然语言中，一致性检查全程都是LLM推理。
实体识别、属性识别、时间提取、值比较——全部是概率性的且昂贵。

在结构化表示中，实体标识符、属性类型和时间字段存在，
所以矛盾检测的大部分转化为字段比较和算术。
解决策略也被声明为策略。

一致性检查在管道中位于过滤之后。
校验和过滤必须先缩小集合，比较对的数量才能减少。
廉价的先行，集体检查在个体检查完成之后。
