---
title: "Почему естественный язык создаёт галлюцинации?"
weight: 8
date: 2026-02-26T12:00:16+09:00
lastmod: 2026-02-26T12:00:16+09:00
tags: ["естественный язык", "галлюцинации", "неоднозначность"]
summary: "Галлюцинация — не баг LLM, а структурная неизбежность четырёх пороков естественного языка: неоднозначности, отсутствия источника, достоверности и времени. Более крупные модели не устранят её."
author: "Junwoo Park"
authorLink: "https://parkjunwoo.com/1/about"
image: "/images/og-default.webp"
---

## Галлюцинация -- не баг. Это структурная неизбежность, пока мы используем естественный язык.

---

## Чудо естественного языка

100 000 лет назад появилась устная речь. Социальные связи, которые приматы могли поддерживать взаимным грумингом, были ограничены примерно 150 особями. Язык разрушил этот потолок. Как только один человек смог говорить одновременно с многими, стал возможен новый масштаб общества -- племя.

10 000 лет назад сельское хозяйство создало запасы пищи, и люди собрались в одном месте, чтобы образовать города. 5 000 лет назад кто-то в Месопотамии вдавил клиновидные знаки во влажную глиняную табличку. Это было для учёта зерна. Рождение письменности. Речь исчезает, но записи сохраняются. Когда записи стали долговечными, стала возможной бюрократия, стало возможным право, стало возможным государство.

Устная речь создала племя. Письменность создала государство.

Естественный язык -- величайшая технология, когда-либо созданная человечеством. Не открытие огня, не изобретение колеса, не изобретение полупроводника. Всё это стало возможным именно благодаря естественному языку. Потому что существовал естественный язык, знания могли передаваться, кооперация могла происходить, а мысли мёртвых могли наследоваться живыми. Десятки тысяч лет естественный язык был средой всей человеческой цивилизации.

И вот теперь этот великий естественный язык стал узким местом эпохи ИИ.

---

## Заблуждение под названием "галлюцинация"

Когда ИИ говорит нечто ложное, мы называем это "галлюцинацией".

В этом названии заложены импликации.
Импликация, что галлюцинация -- это аномалия.
Импликация, что её можно исправить.
Импликация, что лучшая модель это решит.

Это заблуждение.

Галлюцинация -- не баг LLM.
Галлюцинация -- структурная неизбежность, которой не избежать,
пока естественный язык используется как язык рассуждений ИИ.

Сколько бы вы ни масштабировали модель,
сколько бы ни расширяли данные,
как бы ни совершенствовали RLHF,
пока на входе естественный язык и на выходе естественный язык --
галлюцинация не исчезнет.

Позвольте объяснить почему.

---

## Четыре структурных порока естественного языка

Естественный язык эволюционировал для коммуникации между людьми.
Четыре характеристики, приобретённые в этом процессе,
становятся фатальными пороками в рассуждениях ИИ.

---

### Порок 1: Неоднозначность

"He went to the bank."

"Bank" -- это финансовое учреждение или берег реки?
Кто такой "he"?
Когда он туда пошёл?

Люди разрешают это с помощью контекста.
Ход разговора, выражение лица говорящего, общие фоновые знания.

У ИИ есть только текст.
Один текст не может полностью разрешить неоднозначность.
Если разрешить невозможно, ИИ угадывает.
Угадывания иногда ошибочны.
Когда ошибочное угадывание выдаётся с уверенностью -- это галлюцинация.

---

### Порок 2: Отсутствие источника

"Ли Сунсин разбил 133 корабля всего 12-ю."

У этого предложения нет источника.

Кто сделал это утверждение?
Какие исторические записи его подтверждают?
Есть ли учёные разногласия по поводу этих цифр?

В естественном языке нет структурного места для метаданных.
Чтобы включить источники, нужно удлинить предложение,
а удлинение затемняет суть.
Поэтому в большинстве предложений на естественном языке источники опускаются. Эта проблема подробнее рассмотрена в статье [Почему утверждения, а не факты?](/ru/why/claims-not-facts/).

LLM обучаются на миллиардах таких предложений.
Утверждения с опущенными источниками смешиваются
в один огромный статистический суп.

Проследить основу для числа "12" внутри этого супа
принципиально невозможно.
Раз основу нельзя проследить, безосновательные числа тоже могут быть сфабрикованы.
Это галлюцинация.

---

### Порок 3: Отсутствие достоверности

"Земля круглая."
"Тёмная энергия составляет 68% Вселенной."
"Завтра будет дождь."

Уровни достоверности этих трёх предложений совершенно различны.

Первое -- подавляющий консенсус.
Второе -- текущая лучшая оценка, но теория может измениться.
Третье -- вероятностный прогноз.

Тем не менее в естественном языке все три имеют идентичную грамматическую структуру.
Подлежащее + сказуемое. Повествовательное предложение. Точка.

Естественный язык не может структурно выразить "насколько это достоверно".
Есть наречные средства вроде "возможно", "почти наверняка", "может быть",
но они опциональны, неточны и обычно опускаются.

LLM усваивают все предложения с одинаковым уровнем достоверности.
У модели нет внутренней возможности различить разницу в достоверности
между "Земля круглая" и "тёмная энергия -- 68%".

Поэтому она констатирует оценки как факты,
констатирует гипотезы как устоявшиеся взгляды
и констатирует неопределённое с определённостью.
Это галлюцинация.

---

### Порок 4: Отсутствие временного контекста

"Генеральный директор Tesla -- Илон Маск."

По состоянию на когда?

В 2024 году это верно.
В 2030 -- кто знает.
Если время написания не указано,
определить период действия этого предложения невозможно.

Большинство предложений на естественном языке опускают временной контекст.
"Настоящее время" может означать "прямо сейчас"
или может означать "в целом".

LLM усваивают статьи 2020 года и статьи 2024 года как одинаковые данные.
Поскольку временная информация структурно не сохраняется,
они констатируют прошлые факты как настоящие
или смешивают информацию из разных временных периодов.
Это галлюцинация.

---

## Слияние четырёх пороков

Галлюцинация нарастает взрывообразно, когда четыре порока сходятся.

Проанализируем один вывод LLM.

> "Ли Сунсин уничтожил 330 японских кораблей с 12-ю судами,
> а впоследствии погиб в битве при Норяне, оставив последние слова 'Не объявляйте о моей смерти.'"

В этом предложении:

**Неоднозначность:** Что именно означает "уничтожил"? Потопил? Обратил в бегство? Частично повредил?

**Отсутствие источника:** Какова основа чисел 12 и 330? Разные исторические записи приводят разные цифры -- за какой из них последовали?

**Отсутствие достоверности:** "Не объявляйте о моей смерти" -- это исторически подтверждённое завещание или более позднее устное предание? Уровни достоверности различны, но они перечислены в одном повествовательном предложении.

**Отсутствие временного контекста:** Какую временную точку научного консенсуса отражает эта информация?

LLM заполняет всю эту неоднозначность "наиболее правдоподобной последовательностью токенов".
Правдоподобность -- не точность.
Разрыв между ними -- галлюцинация.

---

## Почему более крупные модели не могут решить это

"Разве галлюцинация не уменьшится, когда выйдет GPT-5?"

Уменьшится. Но не исчезнет.

Более крупные модели усваивают более изощрённые паттерны из большего объёма данных.
Поэтому точность "правдоподобности" возрастает.

Но фундаментальная проблема не меняется.

Пока на входе естественный язык -- неоднозначность остаётся.
Пока обучающие данные -- естественный язык -- источники остаются утраченными.
Пока на выходе естественный язык -- достоверность не выражается.
Пока временная информация отсутствует в структуре -- время остаётся перемешанным.

Даже если масштабировать модель в 100 раз,
структурные пороки естественного языка не увеличиваются в 100 раз --
но они и не достигают нуля.

Это не проблема разрешения. Это проблема среды.

Сколько бы вы ни увеличивали разрешение чёрно-белой фотографии, цвет не появится.
Сколько бы вы ни повышали точность естественного языка,
источник, достоверность и временной контекст не появятся в структуре.

Если вы хотите цвет -- нужна цветная плёнка.
Если вы хотите устранить галлюцинации -- нужен другой язык.

---

## Условия структурного решения

Чтобы решить эти четыре порока, сама структура языка должна быть иной.

**Неоднозначность --> Явная структуризация.**
Когда "He went to the bank" преобразуется в структурированный язык,
"he" разрешается в конкретный SIDX сущности,
а "bank" разрешается в SIDX финансового учреждения или берега реки.
Если разрешить невозможно, явно указывается "не разрешено".
Либо разрешить неоднозначность, либо записать факт её наличия.

**Отсутствие источника --> Встроенный источник.**
Каждое повествование структурно включает сущность-источник.
"Кто сделал это утверждение" -- часть повествования.
Это не опционально. Если поле пустое, оно помечается как пустое.

**Отсутствие достоверности --> Встроенная достоверность.**
Каждый глагольный узел имеет поле достоверности.
"Достоверно", "оценочно", "гипотетично"
структурно указываются как модификаторы глагола.

**Отсутствие временного контекста --> Встроенный временной контекст.**
Каждое повествование включает временной контекст.
"По состоянию на когда это повествование" -- всегда указано.

То, что опущено в естественном языке,
существует как часть структуры в структурированном языке.

Когда опущение невозможно, пространство для галлюцинаций сужается. Этот принцип объясняется в статье [Почему необходимо прояснение](/ru/why/clarification/).
Когда нельзя говорить без основания, безосновательные утверждения не производятся.

---

## Конец галлюцинаций -- в замене языка

Рассмотрим текущие подходы к уменьшению галлюцинаций.

**RAG (Retrieval-Augmented Generation):** Извлекает внешние документы и предоставляет их как контекст. Эффективно, но извлечённые документы тоже на естественном языке, поэтому проблемы неоднозначности, отсутствия источников и достоверности переносятся без изменений. Подробнее об этом ограничении — в статье [Почему RAG недостаточно](/ru/why/rag-not-enough/).

**RLHF:** Обучает модель говорить "Я не знаю", когда она не уверена. Уменьшает частоту галлюцинаций, но не решает фундаментальную проблему отсутствия структуры достоверности в естественном языке.

**Chain-of-Thought:** Записывает процесс рассуждения на естественном языке. Направление верное, но среда записи -- естественный язык, поэтому она наследует те же пороки.

Все эти подходы пытаются смягчить галлюцинации в рамках естественного языка.
Они работают. Но они не фундаментальны.

Фундаментальное решение -- убрать естественный язык изнутри ИИ.

Интерфейс с пользователями остаётся на естественном языке.
Люди продолжают говорить на естественном языке и получать ответы на естественном языке.

Но язык, на котором ИИ рассуждает, записывает и верифицирует внутри себя,
должен быть чем-то иным, нежели естественный язык.

Языком, где источник -- в структуре.
Языком, где достоверность -- в структуре.
Языком, где временной контекст -- в структуре.
Языком, где неоднозначность обрабатывается явно.

Устная речь создала племя.
Письменность создала государство.
Что создаст третий язык?

Конец галлюцинаций -- не в более крупных моделях,
а в лучшем языке.

---

## Резюме

Галлюцинация рождается из четырёх структурных пороков естественного языка.

1. **Неоднозначность:** Неразрешима без контекста. ИИ угадывает, и угадывания ошибочны.
2. **Отсутствие источника:** Основа утверждений утрачена. Фабрикуются безосновательные комбинации.
3. **Отсутствие достоверности:** Факты и оценки выражаются одинаковой грамматикой. ИИ не может их различить.
4. **Отсутствие временного контекста:** Информация из разных временных периодов перемешивается.

Более крупные модели уменьшают галлюцинации, но не могут их устранить.
Без смены среды структурные пороки остаются.

Сколько бы вы ни увеличивали разрешение чёрно-белой плёнки, цвет не появится.
Если вы хотите цвет -- нужно сменить плёнку.
