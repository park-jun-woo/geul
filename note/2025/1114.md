# [GEUL] 연구 일지: 2025-11-14

**Project Stream:** `GEUL`
**Author:** 박준우(mail@parkjunwoo.com)

---

## 용어

1.  **GEUL (General Embedding vector Unified Language):** AI 시대를 위한 새로운 '글자'. 모호성이 제거된 2바이트(65,536종) 기반의 인공 언어이자 데이터 스트림 포맷.
2.  **SEGLAM (Self-Examination GEUL Architecture Model):** GEUL을 사용하여 '사유하는 아키텍처'. '추론 → 기록 → 성찰 → 개선'의 선순환 구조를 통해 환각과 블랙박스 문제를 해결하는 것을 목표로 함.
3.  **GDBMS (GEUL Database Management System):** SEGLAM 아키텍처의 중앙 지식베이스. 명시적인 `정보 GEUL Stream`(사실)과 `제어 GEUL Stream`(절차)을 저장함.
4.  **ltree (Label Tree):** PostgreSQL 확장 모듈로, `.`으로 구분된 레이블 경로를 통해 트리 구조(예: 동사 계층)를 효율적으로 저장하고 쿼리하는 데 사용됨.
5.  **의미소 분해 (Sememe Decomposition):** 동사와 같은 단어의 의미를 'verb\_type'(change, state, activity 등), 'Volitionality'(의도성) 등 더 작은 의미 단위(sememe)와 한정자(qualifier)로 분해하는 작업.

---

## ☀️ 아침: 오늘의 목표 (Objectives)

1.  GEUL 공개전략 작성 **(완료)**
2.  GEUL 마일스톤 작성 **(완료)**
3.  GEUL EdgeType 스펙 정의(보류)
4.  GEUL 동사 의미정렬식별자 사전 구축 **(진행 중)**

---

## ⏱️ 진행 과정 및 발견 (Process & Findings)

1.  **GEUL/SEGLAM 핵심 가치 및 전략 분석 (목표 1, 2 연관)**
    * 제공된 GEUL/SEGLAM 관련 문서(개요서, 공개전략, 논문 등)를 기반으로 프로젝트의 핵심 가치를 분석함.
    * **핵심 가치:** 기존 LLM의 '블랙박스' 및 '환각' 문제를 '지식의 화이트박스화', '추론과 절차의 분리', '자기 성찰 루프'를 통해 해결하는 것에 있음을 확인함.
    * **경제적 가치:** 단일 AI 제품이 아닌, AI 산업의 '표준 인프라'를 목표로 함. 성공 시 고부가가치 시장(금융, 의료) 개척 및 AI 운영 비용(OPEX) 절감을 통해 1조 달러 규모의 파급력도 타당성이 있음을 확인함.

2.  **GEUL 동사 사전 계층 구조 구축 (목표 4 진행)**
    * 'GEUL 동사 의미정렬식별자 사전 구축'의 일환으로, 제공된 WordNet DB 스키마(`wordnet.sql`)와 로더(`postgres.py`)를 분석하여 동사 계층 구조화 방안을 수립함.
    * PostgreSQL의 `ltree` 확장을 활용한 `verb_hypernym_ltree` 테이블 설계를 완료함.
    * 제공된 `vervtree.py` 스크립트 및 실행 로그를 분석하여, 13,767개의 동사 synset이 `ltree` 테이블에 성공적으로 구축되었음을 확인함.

3.  **발견 (1): 559개의 '루트 동사' 식별**
    * `vervtree.py` 실행 결과, 13,767개의 동사가 **559개의 루트 동사**(depth=1, 상위 동사가 없는 최상위 개념)를 기반으로 최대 깊이 13의 계층 구조를 형성함을 발견함.
    * 이는 대부분의 동사 개념이 이 559개 핵심 동사의 하위어(hyponym)로 파생됨을 의미함.

4.  **발견 (2): '구조(ltree)'와 '의미(Sememes)'의 결합 가능성**
    * `ltree`로 식별된 559개의 *구조적 루트 동사*를 제공된 40,000여 개의 *의미소 분해 JSON* 파일과 결합할 방안을 도출함.
    * JSON 내 `sememes.verb_type` (예: "activity", "change"), `qualifiers.Volitionality` (의도성, 1.0 vs -1.0), `participants.semantic_role` (예: "causal\_agent") 등의 피처를 활용.
    * **(결론)** 이 피처들을 통해 559개의 루트 동사를 "의도적 행위(Volitional Action)", "비의도적 사건(Non-Volitional Event)" 등과 같은 핵심 **시맨틱 그룹**으로 재분류할 수 있음.
    * **(결론)** 이 분류 과정은 40,000여 개 AI 생성 JSON 데이터의 품질을 교차 검증(QA)하는 수단으로도 활용 가치가 높음.

5.  **[설계] GEUL 동사 14비트 ID 매핑 전략 수립 (목표 4)**
    * **문제 정의:** `vervtree.py`로 구조화된 13,767개의 동사 synset을 `GEUL 스트림 포맷`에서 정의한 14비트(16,383 슬롯) `Verv Type` 공간에 매핑해야 함.
    * **핵심 원칙:** 단순한 알파벳순 나열이 아닌, `verb_hypernym_ltree`에서 구축한 **시맨틱 계층 구조(semantic hierarchy)**를 ID 자체에 반영해야 함. 이는 GEUL의 '화이트박스' 및 '재현성' 원칙에 부합함.
    * **매핑 전략:** 559개의 루트 동사(`depth = 1`)에 14비트 공간의 최상위 ID(예: 1~559)를 우선 할당. 특정 루트의 `ltree` 하위 경로에 속하는 동사들은 해당 루트 ID의 하위 비트 공간에 순차적으로 할당.
    * **의의:** 이 전략적 매핑 과정은 **"동사 의미정렬 식별자"의 핵심 근거**가 되므로, 전 과정을 연구 일지에 상세히 기록해야 함. ID만으로 동사의 최상위 시맨틱 분류를 추론할 수 있게 됨.

6.  **[설계] 41,000+ 동사 의미소 JSON 분석 계획 (목표 4)**
    * **문제 정의:** 41,625개의 AI 생성 의미소 분해 JSON 파일은 파일 시스템에서 직접 분석하기 비효율적임.
    * **해결 방안:** PostgreSQL의 **`JSONB`** 타입을 활용한 DB 적재 결정. `verb_sememes_jsonb` 테이블 설계를 통해 SQL로 시맨틱 피처(verb\_type, Volitionality 등)를 집계.
    * **기대 효과:** DB에서 `verb_hypernym_ltree`와 `verb_sememes_jsonb`를 `synset_id`로 JOIN하여, '구조(ltree)'와 '의미(sememes)'를 결합한 강력한 분석(예: 559개 루트의 시맨틱 그룹핑)이 가능해짐.

7.  **[진행] 41,625개 JSON 데이터 유효성 검사 (QA 작업)**
    * **필요성:** AI 생성 데이터는 DB 적재 전, `factorize_prompt.json`의 명세를 기준으로 반드시 검증(Validation)해야 함.
    * **스크립트 실행:** `check.py` 스크립트를 41,625개 `factorized` 파일 전체에 대해 실행함.
    * **[발견] 11.5%의 비표준 데이터 식별:**
        * 총 **4,777개** 파일(전체의 약 11.5%)에서 5,032개의 오류가 발견됨.
        * 오류 파일들은 `geulso/factorize/checked/` 디렉터리에 `"errors"` 키가 추가된 상태로 격리 저장됨.
    * **[발견] 핵심 오류 유형 (시맨틱 비일관성):**
        * 오류 샘플 분석 결과, `sememes.verb_type`이 `factorize_prompt.json`의 기본 원칙('change', 'state', 'action', 'property')에서 벗어나, 'manner', 'circumstance' 등의 값을 갖는 경우가 다수 발견됨.
        * 이는 AI가 `act_v_02.f.01.json`처럼 'manner'를 `verb_type: "property"`의 `verb_property`로 일관되게 분해하지 않고, `verb_type` 필드 자체에 잘못 할당한 비일관성으로 판단됨.
    * **(결론)** DB 적재 전 4,777개의 비표준 파일을 성공적으로 격리했으며, 이는 데이터 정제 및 AI 생성 모델 재조정(fine-tuning)에 필수적인 피드백으로 활용됨.