# [GEUL] 연구 일지: 2026-02-27

**Project Stream:** `GEUL`
**Author:** 박준우(mail@parkjunwoo.com)

---

## 동사 코드북 생성 완료

### 파이프라인 실행

기존에 코드만 작성하고 미실행 상태였던 동사 코드북 파이프라인을 완성.

| 순서 | 스크립트 | 역할 | 상태 |
|------|---------|------|------|
| 1 | `verbtrees.py` | 559 루트별 hyponym 트리 추출 → `verbtrees/*.json` | 기존 완료 |
| 2 | `sub_primitive_count.py` | sub_primitive별 동사 수 집계 → `json/sub_primitive_count.json` | 기존 완료 |
| 3 | `verbtrees_bit.py` | DFS Pre-order 16비트 코드 할당 → `json/verb_bits.json` | **금일 실행** |
| 4 | `valid_verb_bits.py` | 코드 유효성 검증 | **금일 실행, 통과** |

`verbtrees_bit.py`, `valid_verb_bits.py`의 파일 경로가 `json/` 하위를 가리키지 않아 수정 후 실행.

### 산출물

**`geulso/wordnet/json/verb_bits.json`** — 13,767개 전체 동사 16비트 코드북

```
검증 결과:
  총 동사 수: 13,767
  고유 ID 수: 13,767
  고유 코드 수: 13,767
  오류: 0 / 경고: 0 → 검증 통과
```

### 코드 구조

```
16비트 = sub_primitive prefix (가변 4~8비트) + DFS 순번 코드 (가변 8~12비트)
```

- `primitive-map.json`의 허프만 스타일 가변 prefix: 고빈도 sub_primitive에 짧은 코드
- sub_primitive 내에서 559 루트의 hyponym 트리를 DFS Pre-order 순회하며 순번 부여
- 같은 sub_primitive 내 모든 루트가 하나의 번호 공간 공유
- 중복 동사(여러 트리에 출현)는 먼저 할당된 코드 유지

### prefix별 사용률

| prefix 길이 | sub_primitive 수 | 코드 공간 | 사용률 범위 |
|-------------|-----------------|-----------|------------|
| 4비트 | 4 | 4,096 | 23~75% |
| 5비트 | 4 | 2,048 | 22~37% |
| 6비트 | 8 | 1,024 | 17~40% |
| 7비트 | 16 | 512 | 12~29% |
| 8비트 | 36 | 256 | 1~22% |

모든 sub_primitive에서 확장 여유 충분.

### 우아한 열화 분석

현재 구조의 열화 단계:

```
bit[1-4]  Primitive 수준 (10종: BE, CAUSE, CHANGE, ...)
bit[1-8]  Sub-primitive 수준 (68종: CHANGE-TRANSFORM, CAUSE-USE, ...)
bit[1-16] 개별 동사 (13,767종)
```

**워드넷 트리 기반 허프만 인코딩 검토 결과:**

워드넷 hyponym 트리를 그대로 비트 경로로 인코딩하면 우아한 열화가 모든 계층에서 작동하지만, 실용 불가.

- 트리가 너무 넓음: change.v.01 직계 자식 401개 → 첫 분기만 9비트
- 42.2%의 동사가 가용 비트 초과
- 최대 경로 40비트 (16비트 예산의 2.5배)

**결론:** Primitive → Sub-primitive 2단계 의미 열화로 실용적 충분. 워드넷 트리는 언어학 분류 기준이라 비트 인코딩에 최적화된 구조가 아님.

---

## 동사 코드북 평가

### Verb Edge 명세와의 정합성

Verb Edge 명세서(docs/문법/Verb Edge.md)의 동사 본문 16비트와 verb_bits.json 코드북이 정확히 일치.

- Tiny Verb Edge (2워드): 마지막 워드 = 동사 본문 16비트
- Short Verb Edge (3워드): 마지막 워드 = 동사 본문 16비트
- Full Verb Edge (5워드): 마지막 워드 = 동사 본문 16비트

세 모드 모두 **마지막 워드가 동사 본문 16비트로 통일**. verb_bits.json이 Verb Edge의 정본(canonical) 동사 코드.

Verb Edge.md 섹션 6.3이 `verb_bits.json`을 참조 파일로 직접 명시.

### 장점

1. **Verb Edge 3단 압축과 완벽한 정합**: Tiny/Short/Full 모두 동사 본문이 독립 16비트 워드
2. **허프만 prefix 효율**: 고빈도 sub_primitive(CHANGE-TRANSFORM)에 4비트, 저빈도에 8비트
3. **13,767개 무충돌**: 전수 검증 통과
4. **확장 여유**: 최대 사용률 74.8%, 나머지 10~40%. 다국어 확장·신조어 추가 가능

### 한계

1. **우아한 열화가 Sub-primitive까지만 작동**: DFS 순번은 의미 없는 순서 번호. 비트 마스크 범위 검색이 sub_primitive 수준까지만 유효
2. **DFS 순서에 의미적 근접성 없음**: verbtrees 파일명 알파벳순 × DFS pre-order. 인접 코드의 동사가 의미적으로 유사하지 않음

### 32비트 Verb SIDX와의 관계

| 인코딩 | 구조 | 범위 | 용도 |
|--------|------|------|------|
| 32비트 SIDX (sidx559.json) | `11000010` + primitive + sub_prim + index + pad | 559 루트 | 독립 식별자 |
| 16비트 verb body (verb_bits.json) | sub_prim Huffman + DFS index | 13,767 전체 | Verb Edge 패킷 |

두 인코딩의 비트 배치가 다르나 용도가 분리되어 있어 혼동 없음. Verb Edge 패킷에는 16비트 verb body만 사용.

### 총평

**Proposal 단계로 실용적 충분.** 의미 검색은 WMS 인덱스가 담당하고, 스트림 안에서는 정확한 동사 식별만 되면 됨. 그 목적에 충분.

---

## Verb Edge 설계 검토

### 3단 압축 구조 평가

Tiny(2워드)/Short(3워드)/Full(5워드) 3단 압축은 허프만 원리에 부합하는 합리적 설계. 동사 본문 16비트가 항상 마지막 독립 워드인 것도 깔끔함.

### Tiny 한정자 패턴 문제

현재 Tiny 한정자 7패턴:

| 코드 | 시제 | 극성 | 상 |
|------|------|------|-----|
| 0 | 현재 | 긍정 | 단순 |
| 1 | 과거 | 긍정 | 단순 |
| 2 | 미래 | 긍정 | 단순 |
| 3 | 현재 | 부정 | 단순 |
| 4 | 과거 | 부정 | 단순 |
| 5 | 현재 | 긍정 | 진행 |
| 6 | 과거 | 긍정 | 완료 |

**빠진 중요 요소:**
- Voice(능동/수동) — "문이 열렸다" vs "그가 문을 열었다"
- Modality(양태) — "해야 한다", "할 수 있다", "할지도 모른다"
- Mood(서법) — 의문문, 명령문

이들은 분야 불문 빈번. Tiny에 없으면 Short로 올라가는 비율이 높아져 90% 커버율 달성이 의심됨.

### Tiny 폐지 vs 재설계 검토

**Tiny 폐지 시:**
- Verb Edge prefix `0001 01`(6비트) → `0001 1`(5비트)로 1비트 절약
- Short 1워드에서 1비트 여유 (참여자 10비트 또는 Voice/Modality 추가)
- 대신 평균 패킷 크기 2.16워드 → ~3.06워드 (42% 증가)

**결론: Tiny 유지하되 패턴 재설계가 바람직.**

Tiny 포맷 자체는 유효. 문제는 한정자 7패턴이 빈약한 것. 참여자 패턴을 줄이고 한정자에 수동태·양태·의문을 넣으면 커버율 개선 가능. 최적 배분은 코퍼스 검증 후 결정.

```
현재: 참여자 16패턴 × 한정자 7패턴 = 112 (11비트 내)
대안: 참여자 12패턴 × 한정자 11패턴 = 132 (11비트 내)
```

### 커버율 검증 방법론

**CC NEWS 단독 검증은 부적절.** 뉴스는 3인칭·서술·과거/현재·긍정에 편향됨. Tiny 95%+ 나와도 확인편향.

다양한 분야 테스트 필요:

| 분야 | Tiny에 불리한 패턴 |
|------|-------------------|
| 소설/대화체 | 의문문, 명령문, 감탄문 |
| 법률/계약 | 조건문, 수동태 중첩 |
| 과학 논문 | 수동태 + 완료 + 부정 |
| 철학/논증 | 양태 표현 다수 |
| 일상 대화 | 진행형, 반복, 의도 |

**선행 조건:** Entity 코드북 완성 → 인코더 구현 → 다분야 코퍼스 변환 → Tiny/Short/Full 분포 측정

---

## 동사 데이터 소재 정리

| 데이터 | 위치 | 규모 |
|--------|------|------|
| 559 루트 SIDX | `geulso/wordnet/verbtop559/sidx559.json` | 559개 |
| 559 루트 분류 | `geulso/wordnet/verbtop559/verbclassified559.json` | 559개 |
| prefix 매핑 | `geulso/wordnet/json/primitive-map.json` | 68 sub_primitive |
| flat index | `geulso/wordnet/json/flat-verbs.json` | 559개 |
| 하위 트리 | `geulso/wordnet/verbtrees/*.json` | 559 파일 |
| **동사 코드북** | **`geulso/wordnet/json/verb_bits.json`** | **13,767개** |
| 동사 계층 (DB) | `geuldev.verb_hypernym_ltree` | 13,767행 |
| 동사 의미소 (DB) | `geuldev.wordnet_factorized_sememes` | ~33K행 |

---

## Entity type_schemas.json 전체 설계 검토

### 현황 수치

| 항목 | 수치 |
|------|------|
| 정의된 타입 | 63 / 64 (0x3F_Other 제외) |
| 총 필드 수 | 738 |
| Property 매핑 있음 | 324 (43.9%) |
| Property 매핑 없음 | 414 (56.1%) |
| flags 필드 | 41개 타입, 총 82비트 (용도 미정) |
| 주관적 필드 | 8개 (fame/notability/popularity 등) |

### 구조적 건전성: 통과

- 63개 타입 전부 48비트 정확, 오프셋 무결
- 카테고리별 공통 헤더 패턴이 일관적

### 공통 헤더 패턴 (장점)

| 카테고리 | 타입 범위 | 공통 헤더 | 크기 |
|----------|----------|----------|------|
| 지형 | 0x14-0x1B | country+lat+lon+admin | 22비트 |
| 정주지 | 0x1C-0x23 | country+admin_level+admin_code+lat+lon | 28비트 |
| 건물 | 0x24-0x2B | country+admin_code+era | 20비트 |
| 창작물 | 0x30-0x38 | country+year+genre | 20~21비트 |

비트 마스크 범위 검색 시 카테고리 내 우아한 열화가 작동.

### 심각한 문제

**1. Property 매핑률 43.9%**: 56.1% 필드를 위키데이터에서 자동 채울 수 없음. Moon(0%), Compound(13%), Planet(17%) 최악.

**2. 주관적/자동화 불가 필드**: notability, artist_fame, director_fame, composer_fame, popularity, celebrity_assoc, developer_fame — 정의 모호, 데이터 소스 없음.

**3. 과도한 세분화**: Settlement/Village/Hamlet(거의 동일 스키마), Mountain/Hill, River/Stream — 5~8 슬롯 낭비.

**4. 누락된 중요 타입**: Country, City, University, Hospital, Airport, Museum 등. Country 누락이 Phase 6에서 62.2% 미분류의 직접 원인.

### 결론

스키마 구조 자체는 건전하나, "이상적 속성 목록"으로 설계되어 실제 데이터 소스와 괴리. 리셋보다는 정비 수준:

1. 과도한 세분화 타입 통합 → 5~8 슬롯 확보
2. 확보 슬롯에 Country, City 등 추가
3. Property 매핑률 0% 타입 재설계
4. 주관적 필드 제거, flags 용도 정의

---

## Entity SIDX 검색 아키텍처

### 공통 헤더 전역 고정은 불가

63개 전체가 공유하는 필드: **0개.** 가장 많은 `country`도 45/63(71%)만.

country 없는 18타입 (14.9M개체, 13.6%):
- 생물종(Taxon): 개는 어느 나라 소속? → 무의미
- 화학물질(Chemical, Compound): H₂O에 국적? → 무의미
- 천체(Star, Galaxy, Moon 등): 별에 국가? → 무의미

공통 헤더 강제는 **"비트 자체에 의미를 인코딩"** 원칙에 위배. 타입별 독립 스키마 유지가 올바른 설계.

### SIMD 비트마스크 검색 전략: 코드북 leaf Dictionary

**쿼리 마스크 조립 문제:**
- 64타입 × 독립 스키마 → country 오프셋이 타입마다 다름
- 공통 헤더 없이 크로스타입 쿼리를 어떻게?

**해법: 코드북 leaf를 dictionary map으로 운용**

```
pre-built dictionary (~35,000 entries, ~1MB, L2 캐시 적재):
  ("Human", "country", "Korea")  → { mask: 0x..., value: 0x... }
  ("Star", "constellation", "Orion") → { mask: 0x..., value: 0x... }
```

마스크 조립: 조건 수 K에 대해 O(K). K=1~5이므로 사실상 O(1).
SIMD 스캔: 타입별 분리 저장 시 Human 12.5M → ~2ms, Star 3.6M → ~0.6ms.

### 쿼리 파이프라인: LLM + Dictionary 역할 분리

```
User: "1950년대 한국 남성 정치인"
       ↓
[소형 쿼리 LLM]  ← 의미 파싱만 (확률적)
       ↓
키워드 배열:
  { "type": "Human",
    "conditions": [
      {"field": "country",    "value": "Korea"},
      {"field": "gender",     "value": "Male"},
      {"field": "occupation", "value": "Politician"},
      {"field": "era",        "value": "1950s"}
    ]}
       ↓
[키워드 검증]  ← 결정론적, 존재 여부 즉시 확인
       ↓
[Dictionary 조립]  ← 결정론적, O(K)
       ↓
mask + value
       ↓
[SIMD 스캔]  ← Human 배열만, ~2ms
       ↓
결과 SIDX 목록
```

### LLM이 비트마스크를 직접 생성하면 안 되는 이유

- 35,000개 leaf의 오프셋/비트폭 기억 불가
- 1비트 오류 → 완전히 다른 결과
- 비트열은 검증 불가

### 키워드 배열의 이점

1. **검증 가능**: 각 키워드의 존재 여부를 즉시 확인
2. **퍼지 매칭**: "South Korea" → "Korea" 보정 가능 (비트마스크에선 불가)
3. **설명 가능**: 사용자에게 자연어로 쿼리 내용 확인 요청 가능

### 쿼리 LLM 컨텍스트 규모

타입 먼저 결정 후 해당 타입 어휘만 로드:

| 단계 | 내용 | 토큰 |
|------|------|------|
| 1 | 64개 타입명 → 타입 결정 | ~100 |
| 2 | 해당 타입 필드 어휘 로드 | ~550 |
| 3 | 조건 매칭 (필드+값 선택) | - |

**~550토큰이면 3B급 소형 LLM으로 충분.**

### 복잡도 정리

| 단계 | 담당 | 성격 | 복잡도 |
|------|------|------|--------|
| 의미 파싱 | 소형 LLM | 확률적 | ~550토큰 |
| 키워드 검증 | 코드 | 결정론적 | O(K) |
| 비트마스크 조립 | Dictionary | 결정론적 | O(K) |
| 검색 | SIMD | 하드웨어 | O(N), ~ms |

### 설계적 결론

타입별 독립 스키마 738필드 자체는 문제가 아님. 코드북 어휘 사전(dictionary)만 잘 구축하면 검색 실용성 확보. 현재 `codebooks_full.json`을 확장하면 됨.

---

## 쿼리 LLM 파인튜닝 난이도 평가

### 태스크 본질

```
입력: 자연어 문장
출력: JSON (type 1개 + field:value 쌍 1~5개)
```

NER + 슬롯 필링. Siri/Alexa의 의도 분류("서울 내일 날씨"→`{intent:weather, city:Seoul}`)와 동일 수준.

### 출력 공간이 극도로 제한적

- type: 64개 중 1개
- field: 해당 타입 ~11개 중 선택
- value: 해당 필드 ~50개 중 선택

자유 텍스트 생성이 아닌 **닫힌 어휘 선택**. 환각 여지 거의 없음.

### 학습 데이터 자동 생성

코드북 35,000 leaf에서 역방향 생성 가능. GPT-4로 자연어 변형 × 10 = 35만 쌍. 하루 만에 생성.

### 모델 규모

| 유사 태스크 | 모델 규모 |
|------------|----------|
| 의도 분류 + 슬롯 필링 (Alexa) | 수백MB |
| Text-to-SQL (SQLCoder) | 7B |
| NER (GLiNER) | 300M |

GEUL 쿼리 파싱은 출력 공간이 더 좁으므로 **1~3B + LoRA면 충분**.

### 파인튜닝 없이도 가능

코드북 어휘 550토큰 → 프롬프트에 전부 적재 가능. Phi-3 Mini(3.8B)나 Gemma-2B도 few-shot으로 동작하는 수준. 파인튜닝은 속도/정확도 최적화 단계에서 진행하면 됨.
